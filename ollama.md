# Ollama ç°¡ä»‹ ğŸ¤–

* [Youtube Tutorial - Ollama ç°¡ä»‹å®‰è£æ•™å­¸ ä»¥åŠ GGUF æ ¼å¼](https://youtu.be/yi4AyYju0vQ)

![alt tag](https://ollama.com/public/blog/embedding-models.png)

Ollama å¯ä»¥ç°¡å–®ç†è§£ç‚º AI ç•Œçš„ Dockerã€‚

ä¸‹è¼‰æ–¹å¼ ğŸ’¾ , é€™é‚Šæ˜¯ linux

[https://ollama.com/download](https://ollama.com/download)

å¦‚æœä½ å®‰è£å®Œ, å®ƒç™¼ç¾ä½ çš„é›»è…¦æ²’æœ‰ GPU, æœƒé¡¯ç¤ºä»¥ä¸‹çš„å…§å®¹æé†’ä½ , ä½†é‚„æ˜¯å¯ä»¥ä½¿ç”¨ âš ï¸âš ï¸

```text
WARNING: No NVIDIA/AMD GPU detected. Ollama will run in CPU-only mode.
```

æŸ¥çœ‹ä½ çš„ç‰ˆæœ¬

```cmd
> ollama -v
ollama version is 0.6.2
```

Ollama é è¨­ä½¿ç”¨çš„åŸ è™Ÿ (port) æ˜¯ `11434` ğŸ”Œ

## ä»€éº¼æ˜¯ GGUF æ ¼å¼ï¼Ÿ ğŸ“„

åœ¨ Ollama ä¸­ä¸‹è¼‰å’ŒåŸ·è¡Œçš„æ¨¡å‹ï¼Œé€šå¸¸éƒ½æ˜¯ GGUF æ ¼å¼ã€‚

GGUF (GPT-Generated Unified Format) æ˜¯ä¸€ç¨®ç‰¹åˆ¥ç‚ºå¤§å‹èªè¨€æ¨¡å‹è¨­è¨ˆçš„æª”æ¡ˆæ ¼å¼ã€‚

æŠŠå®ƒæƒ³åƒæˆä¸€å€‹ AI æ¨¡å‹çš„ã€Œå£“ç¸®æª”ã€æˆ–ã€Œå®¹å™¨ã€ï¼šå®ƒæŠŠé‹è¡Œæ¨¡å‹æ‰€éœ€çš„æ‰€æœ‰æ±è¥¿ï¼ˆæ¨¡å‹çš„åƒæ•¸ã€çµæ§‹ã€åˆ†è©å™¨è³‡è¨Šç­‰ï¼‰æ‰“åŒ…åœ¨ä¸€å€‹å–®ä¸€æª”æ¡ˆè£¡ã€‚

ä¸»è¦å„ªé»ï¼šè®“æ¨¡å‹æ›´å®¹æ˜“ã€æ›´å¿«é€Ÿåœ°åœ¨å„ç¨®ä¸åŒçš„ç¡¬é«”ä¸Šè¼‰å…¥å’ŒåŸ·è¡Œï¼Œç‰¹åˆ¥æ˜¯åœ¨ä¸€èˆ¬çš„ CPU æˆ–ä¸åŒå“ç‰Œçš„ GPUï¼ˆNVIDIA, AMD, Apple Silicon ç­‰ï¼‰ä¸Šï¼Œ

ä¸éœ€è¦è¤‡é›œçš„è¨­å®šã€‚å®ƒçš„è¨­è¨ˆå„ªåŒ–äº†è¼‰å…¥é€Ÿåº¦å’Œè¨˜æ†¶é«”ä½¿ç”¨æ•ˆç‡ã€‚

èˆ‡ Ollama çš„é—œä¿‚ï¼šOllama ä¸»è¦å°±æ˜¯ä½¿ç”¨ GGUF æ ¼å¼çš„æ¨¡å‹ã€‚ç•¶ä½ åŸ·è¡Œ ollama pull æ™‚ï¼Œä¸‹è¼‰å›ä¾†çš„é€šå¸¸å°±æ˜¯ä¸€å€‹ .gguf æª”æ¡ˆã€‚

## å®‰è£æ¨¡å‹ä»¥åŠæŠŠç© Ollama ğŸš€

å¦‚ä½•ä¸‹è¼‰ models

ä¾‹å¦‚æˆ‘æƒ³è¦ä¸‹è¼‰ deepseek-r1

![alt tag](https://i.imgur.com/qHo6Sik.png)

é€™é‚Šæˆ‘å€‘å…ˆ pull å°±å¥½

```cmd
ollama pull deepseek-r1:1.5b
```

ç„¶å¾Œå¯ä»¥ä½¿ç”¨ `ollama list` æŸ¥çœ‹ç›®å‰çš„æ‰€æœ‰ä»¥ä¸‹è¼‰çš„æ¨¡å‹

```cmd
> ollama list
NAME                       ID              SIZE      MODIFIED
deepseek-coder:latest      3ddd2d3fc8d2    776 MB    2 weeks ago
nomic-embed-text:latest    0a109f422b47    274 MB    2 weeks ago
deepseek-r1:1.5b           a42b25d8c10a    1.1 GB    2 weeks ago
phi3:latest                4f2222927938    2.2 GB    2 weeks ago
```

å¦‚æœä½ æƒ³è©¦ç©æŸå€‹æ¨¡å‹, å¯ä»¥ä½¿ç”¨ run â–¶ï¸

```cmd
> ollama run deepseek-coder:latest
```

![alt tag](https://i.imgur.com/UsLpnT0.png)

ç‚ºäº†è®“å…¶ä»–å·¥å…·ï¼ˆä¾‹å¦‚ Difyï¼‰å¯ä»¥é€£æ¥åˆ° Ollamaï¼Œå»ºè­°è¨­å®š OLLAMA_HOST ç’°å¢ƒè®Šæ•¸ï¼Œ

è®“ Ollama æœå‹™ç›£è½æ‰€æœ‰ç¶²è·¯ä»‹é¢ã€‚

é€™é‚Šä¹Ÿæœ‰å¤§å®¶å¸¸è¦‹çš„ä¸€äº›å•é¡Œ

[How do I configure Ollama server?](https://github.com/ollama/ollama/blob/main/docs/faq.md#how-do-i-configure-ollama-server)

ä¾ç…§ä½ å°æ‡‰çš„ os è¨­å®š, åƒæˆ‘é€™é‚Šæ˜¯ linux

Setting environment variables on Linux

```cmd
sudo systemctl edit ollama.service
```

ç„¶å¾ŒåŠ å…¥

```cmd
[Service]
Environment="OLLAMA_HOST=0.0.0.0:11434"
```

æœ€å¾Œé‡æ–°å•Ÿå‹•

```cmd
sudo systemctl daemon-reload
sudo systemctl restart ollama
```

## Python é€£æ¥ Ollama

ä½¿ç”¨é€™å€‹å¥—ä»¶ [ollama-python](https://github.com/ollama/ollama-python)

```cmd
pip install ollama
```

```python
from ollama import chat
from ollama import ChatResponse

response: ChatResponse = chat(model='deepseek-r1:1.5b', messages=[
  {
    'role': 'user',
    'content': 'ä»€éº¼æ˜¯ docker',
  },
])
print(response['message']['content'])
# or access fields directly from the response object
print(response.message.content)
```

![alt tag](https://i.imgur.com/VngQmcA.png)